{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc4a6bd",
   "metadata": {},
   "source": [
    "# Simple DADVI example\n",
    "\n",
    "This notebook runs DADVI, computes LR covariances, and compares against NUTS for one of the simple models included in PyMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359802e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import pytensor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from jax.config import config\n",
    "\n",
    "# This makes sure we use double precision\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# The next import is the DADVI library.\n",
    "# This is the most convenient function to run.\n",
    "from dadvi.pymc.jax_api import fit_pymc_dadvi_with_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a good example model since it's built into PyMC\n",
    "def fetch_radon_model():\n",
    "\n",
    "    data = pd.read_csv(pm.get_data(\"radon.csv\"))\n",
    "    data[\"log_radon\"] = data[\"log_radon\"].astype(pytensor.config.floatX)\n",
    "    county_names = data.county.unique()\n",
    "    county_idx = data.county_code.values.astype(\"int32\")\n",
    "\n",
    "    n_counties = len(data.county.unique())\n",
    "\n",
    "    with pm.Model() as hierarchical_model:\n",
    "        # Hyperpriors for group nodes\n",
    "        mu_a = pm.Normal(\"mu_a\", mu=0.0, sigma=100.0)\n",
    "        sigma_a = pm.HalfNormal(\"sigma_a\", 5.0)\n",
    "        mu_b = pm.Normal(\"mu_b\", mu=0.0, sigma=100.0)\n",
    "        sigma_b = pm.HalfNormal(\"sigma_b\", 5.0)\n",
    "\n",
    "        # Intercept for each county, distributed around group mean mu_a\n",
    "        # Above we just set mu and sd to a fixed value while here we\n",
    "        # plug in a common group distribution for all a and b (which are\n",
    "        # vectors of length n_counties).\n",
    "        a = pm.Normal(\"a\", mu=mu_a, sigma=sigma_a, shape=n_counties)\n",
    "        # Intercept for each county, distributed around group mean mu_a\n",
    "        b = pm.Normal(\"b\", mu=mu_b, sigma=sigma_b, shape=n_counties)\n",
    "\n",
    "        # Model error\n",
    "        eps = pm.HalfCauchy(\"eps\", 5.0)\n",
    "\n",
    "        radon_est = a[county_idx] + b[county_idx] * data.floor.values\n",
    "\n",
    "        # Data likelihood\n",
    "        radon_like = pm.Normal(\n",
    "            \"radon_like\", mu=radon_est, sigma=eps, observed=data.log_radon\n",
    "        )\n",
    "\n",
    "    return hierarchical_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f860596-ae25-475c-8995-e917df3f9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your PyMC model as usual:\n",
    "# Here we could use any PyMC model instead!\n",
    "m = fetch_radon_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87205e8-d496-4de3-b823-1989f866f8ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit with DADVI using 30 fixed draws.\n",
    "model_result = fit_pymc_dadvi_with_jax(m, num_fixed_draws=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5174704-780d-4ada-a13f-bced665f5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we do this, we get draws from the mean field estimate\n",
    "mean_field_draws = model_result.get_posterior_draws_mean_field()\n",
    "\n",
    "# We could also look at the mean field means and standard deviations\n",
    "mf_means = model_result.get_posterior_means()\n",
    "mf_sds = model_result.get_posterior_standard_deviations_mean_field()\n",
    "\n",
    "# All three are formatted the same way:\n",
    "print(mean_field_draws.keys(), '\\n')\n",
    "print(mean_field_draws['b'].shape, '\\n')\n",
    "\n",
    "print(mf_means.keys(), '\\n')\n",
    "print(mf_sds.keys(), '\\n')\n",
    "print(mf_means['b'].shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The posterior draws differ from the MF optimum only by sampling error.  The advantage\n",
    "# of the draws is in computing expectations of nonlinear functions of the parameters.\n",
    "plt.plot(mf_means['b'], np.mean(mean_field_draws['b'], axis=0), '.')\n",
    "plt.xlabel('Mean field posterior mean')\n",
    "plt.xlabel('Mean of posterior draws')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfe609d",
   "metadata": {},
   "source": [
    "# LRVB correction\n",
    "\n",
    "- `lrvb_sd` is the LRVB estimate of the posterior SD\n",
    "- `freq_sd` is the LRVB estimate of the SD due to the fixed draws\n",
    "- `n_hvp_calls` is the number of hvp calls that were required to compute this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use the identity function, but something else works too via the delta method.\n",
    "# This also computes the frequentist SD estimate.\n",
    "lrvb_corrected = model_result.get_frequentist_sd_and_lrvb_correction_of_scalar_valued_function(lambda x: x['b'][0])\n",
    "print(lrvb_corrected.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b611e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'LR sd =\\t{lrvb_corrected[\"lrvb_sd\"]}')\n",
    "print(f'MF sd =\\t{mf_sds[\"b\"][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec24e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_draws = np.random.normal(loc=lrvb_corrected['mean'], scale=lrvb_corrected['lrvb_sd'], size=(1000, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26beb0",
   "metadata": {},
   "source": [
    "# Run the same model with PyMC NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae485a-ba06-4947-bd95-e0bf74c39296",
   "metadata": {},
   "outputs": [],
   "source": [
    "with m as model:\n",
    "    nuts_res = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e74a8-4d14-4810-9eb0-3b5662fa745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten NUTS into a vector\n",
    "example_variable = nuts_res.posterior['b'].values\n",
    "num_chains, num_draws, _ = example_variable.shape\n",
    "reshaped = example_variable.reshape(num_chains * num_draws, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309492f5",
   "metadata": {},
   "source": [
    "## Compare NUTS with mean field and linear response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5da49d-2a27-412e-aee5-f61feb989889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against mean field\n",
    "plt.hist(reshaped[:, 0], density=True, alpha=0.5, label='NUTS (MCMC)')\n",
    "plt.hist(mean_field_draws['b'][:, 0], density=True, alpha=0.5, label='Mean field')\n",
    "plt.hist(lr_draws, density=True, alpha=0.5, label='Linear response')\n",
    "plt.xlabel('Draws of b[0]')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dadvi",
   "language": "python",
   "name": "dadvi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "88740bce1772f3df3bc0633f0263952339ee060b13f48ed95fadf110f01a10d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
